{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8x1saSiH-C3"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pickle as pkl\n",
        "import pandas as pd\n",
        "import uuid\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqLVN_a8IeyY",
        "outputId": "485587d7-0da3-4252-c39b-5bebdde15a85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive/AVE/BERT_multimodal_transformer/custom_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D056KvewIfvU",
        "outputId": "052591ef-1341-4194-cc52-2adb67563386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AVE/BERT_multimodal_transformer/custom_dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train.tsv', sep='\\t')\n",
        "dev = pd.read_csv('val.tsv', sep='\\t')\n",
        "test = pd.read_csv('test.tsv', sep='\\t')"
      ],
      "metadata": {
        "id": "kuXbGtjiNTC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def attr_spec_sample(df, specified_attr, sample_num=None, sample_ratio=None):\n",
        "        \"\"\" specify attributes and sampling \"\"\"\n",
        "        # Filter the DataFrame based on 'specified_attr'.\n",
        "        df_selected = df[df['attribute_names'].isin(specified_attr)]\n",
        "\n",
        "        # Unique attribute values in column 'attribute_names'\n",
        "        sampled_attribute_value = df_selected['attribute_values'].unique()\n",
        "        num_unique_attr_values = len(sampled_attribute_value)\n",
        "\n",
        "        if sample_num or sample_ratio:\n",
        "            # This will be a dictionary where the keys are unique attribute values and the values are the sampled DataFrames.\n",
        "            sampled_dfs = {}\n",
        "\n",
        "            # We will use groupby to group the DataFrame by 'attribute_values' and then sample K from each group.\n",
        "            for attribute_value, group in df_selected.groupby('attribute_values'):\n",
        "                # Ensure there are at least K examples to sample, otherwise take as many as are available.\n",
        "                if sample_num:\n",
        "                    n_samples = min(len(group), sample_num)\n",
        "                else:\n",
        "                    n_samples = round(len(group) * sample_ratio)\n",
        "                sampled_dfs[attribute_value] = group.sample(n=n_samples)\n",
        "\n",
        "            # Concatenate the individual DataFrames.\n",
        "            df_samples = pd.concat(sampled_dfs.values(), ignore_index=True)\n",
        "        else:\n",
        "            df_samples = df_selected\n",
        "\n",
        "        print('Specified Attribute list: ', specified_attr)\n",
        "        if sample_num:\n",
        "            print('Specified Sample Num Per Attribute Value: ', sample_num)\n",
        "        else:\n",
        "            print('Specified Sample Ratio Per Attribute Value: ', sample_ratio)\n",
        "        print('Split size: ', len(df))\n",
        "        print('Split size after specifying attributes: ', len(df_selected))\n",
        "        print('Split size after sampling: ', len(df_samples))\n",
        "        print('Numumber of Unique Attribute Value: ', len(sampled_attribute_value))\n",
        "        print('Attribute Value List: ', sampled_attribute_value)\n",
        "\n",
        "        return df_samples"
      ],
      "metadata": {
        "id": "s6tPiZ8rI0xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bert_preprocess(df, id_to_visual_embeddings):\n",
        "    data = []\n",
        "\n",
        "    df['prompt'] = df.apply(lambda row: f\"Question: What is {row['attribute_names']} of this product?\\nContext: [Category] {row['category']} {row['value_absent_texts']}.\", axis=1)\n",
        "    id_to_prompts = df.groupby('id')['prompt'].apply(list).to_dict()\n",
        "\n",
        "    unique_attribute_values = df['attribute_values'].unique()\n",
        "    attribute_value_to_label = {value: label for label, value in enumerate(unique_attribute_values)}\n",
        "\n",
        "    df['label'] = df['attribute_values'].map(attribute_value_to_label)\n",
        "    id_to_label = df.groupby('id')['label'].apply(list).to_dict()\n",
        "\n",
        "    for id in id_to_prompts:\n",
        "      if id not in id_to_visual_embeddings:\n",
        "        continue\n",
        "\n",
        "      texts = id_to_prompts[id]\n",
        "      visual = id_to_visual_embeddings[id]\n",
        "      labels = id_to_label[id]\n",
        "\n",
        "      for i in range(len(texts)):\n",
        "        text = texts[i]\n",
        "        label = labels[i]\n",
        "        segment = str(uuid.uuid4())\n",
        "        data.append(((text,visual),label,segment))\n",
        "\n",
        "    return data\n"
      ],
      "metadata": {
        "id": "94wXpc66Nmeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('ave_image_embeddings.pkl', 'rb') as handle:\n",
        "    id_to_visual_embeddings = pkl.load(handle)"
      ],
      "metadata": {
        "id": "nrcATa9mOgmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids_to_keep = set(id_to_visual_embeddings.keys())\n",
        "train = train[train['id'].isin(ids_to_keep)]\n",
        "dev = dev[dev['id'].isin(ids_to_keep)]\n",
        "test = test[test['id'].isin(ids_to_keep)]"
      ],
      "metadata": {
        "id": "YpV8OGAKWQR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subset_mapping = {\"Clothing\":[\"Neckline\", \"Length\", \"Sleeve Style\", \"Shoulder Style\"],\n",
        "                  \"Footwear\":[\"Athletic Shoe Style\", \"Boot Style\", \"Shaft Height\", \"Heel\"],\n",
        "                  \"General\":[\"Pattern\", \"Material\", \"Shape\"]}"
      ],
      "metadata": {
        "id": "yvOSsf-XSdN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in subset_mapping:\n",
        "  curr_dev = attr_spec_sample(dev, subset_mapping[key])\n",
        "  curr_test = attr_spec_sample(test, subset_mapping[key])\n",
        "\n",
        "  curr_dev = bert_preprocess(curr_dev,id_to_visual_embeddings)\n",
        "  curr_test = bert_preprocess(curr_test,id_to_visual_embeddings)\n",
        "\n",
        "  for i in [5,10,15,25,50,100,1000]:\n",
        "    subset = attr_spec_sample(train, subset_mapping[key], sample_num=100)\n",
        "    subset = attr_spec_sample(train, subset_mapping[key], sample_num=i)\n",
        "    curr_train = bert_preprocess(subset,id_to_visual_embeddings)\n",
        "    split_data = {\"train\":curr_train,\n",
        "                  \"dev\": curr_dev,\n",
        "                  \"test\": curr_test}\n",
        "\n",
        "    save_name = f'bert_{key}_{i}_shot.pkl'\n",
        "    with open(save_name, 'wb') as file:\n",
        "      pkl.dump(split_data, file)\n",
        "\n",
        "    print(f'Done with {save_name}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QwswQQzTj8y",
        "outputId": "8ae1a534-43a5-43c4-c344-9959d0e71f4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Specified Attribute list:  ['Neckline', 'Length', 'Sleeve Style', 'Shoulder Style']\n",
            "Specified Sample Ratio Per Attribute Value:  None\n",
            "Split size:  8438\n",
            "Split size after specifying attributes:  2957\n",
            "Split size after sampling:  2957\n",
            "Numumber of Unique Attribute Value:  30\n",
            "Attribute Value List:  ['Halter' 'Gown' '3/4 Sleeve' 'Mini' 'Round Neck' 'Polo' 'Button Down'\n",
            " 'Pencil' 'Midi' 'Cold Shoulder' 'One Shoulder' 'Crew Neck' 'Strapless'\n",
            " 'Skater Skirt' 'Short Dress' 'Henley' 'Strappy' 'Scoop Neck'\n",
            " 'Long Sleeve' 'Long Dress' 'High Neck' 'Capri' 'V-Neck' 'Cowl Neck'\n",
            " 'Off Shoulder' 'Short Sleeve' 'Square Neck' 'Turtleneck' 'Sleeveless'\n",
            " 'Cap Sleeve']\n",
            "Specified Attribute list:  ['Neckline', 'Length', 'Sleeve Style', 'Shoulder Style']\n",
            "Specified Sample Ratio Per Attribute Value:  None\n",
            "Split size:  8349\n",
            "Split size after specifying attributes:  3075\n",
            "Split size after sampling:  3075\n",
            "Numumber of Unique Attribute Value:  30\n",
            "Attribute Value List:  ['Pencil' 'Long Dress' 'Round Neck' 'Turtleneck' 'Short Sleeve' 'Midi'\n",
            " 'Scoop Neck' 'Off Shoulder' 'V-Neck' 'Strapless' 'Polo' 'Long Sleeve'\n",
            " 'Halter' 'Gown' 'Button Down' 'Short Dress' 'Cap Sleeve' 'Henley'\n",
            " 'Sleeveless' 'Capri' 'One Shoulder' 'High Neck' '3/4 Sleeve'\n",
            " 'Cold Shoulder' 'Crew Neck' 'Skater Skirt' 'Cowl Neck' 'Strappy' 'Mini'\n",
            " 'Square Neck']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-bb2c47f5e450>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['prompt'] = df.apply(lambda row: f\"Question: What is {row['attribute_names']} of this product?\\nContext: [Category] {row['category']} {row['value_absent_texts']}.\", axis=1)\n",
            "<ipython-input-41-bb2c47f5e450>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['label'] = df['attribute_values'].map(attribute_value_to_label)\n",
            "<ipython-input-41-bb2c47f5e450>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['prompt'] = df.apply(lambda row: f\"Question: What is {row['attribute_names']} of this product?\\nContext: [Category] {row['category']} {row['value_absent_texts']}.\", axis=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Specified Attribute list:  ['Neckline', 'Length', 'Sleeve Style', 'Shoulder Style']\n",
            "Specified Sample Num Per Attribute Value:  100\n",
            "Split size:  38903\n",
            "Split size after specifying attributes:  13931\n",
            "Split size after sampling:  3000\n",
            "Numumber of Unique Attribute Value:  30\n",
            "Attribute Value List:  ['Long Sleeve' 'Crew Neck' 'Off Shoulder' '3/4 Sleeve' 'Long Dress'\n",
            " 'Pencil' 'Cold Shoulder' 'Midi' 'Cowl Neck' 'Square Neck' 'Skater Skirt'\n",
            " 'Polo' 'Halter' 'Henley' 'Cap Sleeve' 'Short Sleeve' 'Strapless' 'Capri'\n",
            " 'Mini' 'Sleeveless' 'Short Dress' 'Round Neck' 'One Shoulder' 'V-Neck'\n",
            " 'Button Down' 'Gown' 'Scoop Neck' 'Turtleneck' 'Strappy' 'High Neck']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-bb2c47f5e450>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['label'] = df['attribute_values'].map(attribute_value_to_label)\n"
          ]
        }
      ]
    }
  ]
}